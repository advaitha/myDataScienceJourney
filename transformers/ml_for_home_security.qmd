---
title: "Computer Vision Using Transformers"
author: "Thulasiram Gunipati<br>Jan 11, 2023"
format: 
  revealjs:
    footer: "[github/thulasiram](https://advaitha.github.io/myDataScienceJourney)&nbsp;&nbsp;&nbsp;"
    theme: solarized
    preview-links: auto
    chalkboard: 
      boardmarker-width: 5
from: markdown+emoji
execute:
  echo: true
---

## Topics Covered

<br/>

::: {.incremental}
- Core concepts of Attention is all you need
- Implementation details
- Adapting Attention to vision
- Evaluation of Transformers to vision
- Comparison with CNNs
- Use case discussion
:::

---

# Attention is all you need

## Why is it required?

<br/>

::: {.incremental}
- Get required images from the videos 
- Go for diversified data - Different yards, seasons etc.
- Quality over quantity 
:::

---


## Data Preparation

<br/>

::: {.incremental}
- Get required images from the videos 
- Go for diversified data - Different yards, seasons etc.
- Quality over quantity 
:::

---

## Data Labeling

::: {.incremental}
- Rules and standards for the labels
- consistency in labeling 
:::

---

## Training

::: {.incremental}
- Transformers don't have inductive biases
- Transformers are global and flexible
- Training Transformers are expensive
- The way to go is `Transfer learning`
-  
:::

---

## Why Transfer Learning

::: {.incremental}
- Using a pre-trained model is both more cost-efficient and leads to better results
- As pre-trained models use huge amounts of data, Attention mechanism learns where to focus
:::

---

## How to use Transfer Learning

::: {.incremental}
- Using a pre-trained model is both more cost-efficient and leads to better results
- As pre-trained models use huge amounts of data, Attention mechanism learns where to focus


