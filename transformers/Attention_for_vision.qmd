---
title: "Computer Vision Using Transformers"
author: "Thulasiram Gunipati<br>Jan 11, 2023"
format: 
  revealjs:    
    theme: solarized
    preview-links: auto
    chalkboard: 
      boardmarker-width: 5
from: markdown+emoji
execute:
  echo: true
---

## Topics Covered

::: {.incremental}
- Core concepts of `Attention is all you need`
- Adapting Attention to vision
- Use case Implementation
:::

---

## Attention is all you need

---

## Why a new architecture is required?

::: {.incremental}
- RNNs process words sequentially
- RNN cannot consider long sequence lengths
:::

---


## Attention Transformer Architecture

![](/Images/transformer_architecture.png){height=6in}

---

## Blocks of the Architecture

::: {.incremental}
- Embedding layer 
  * Reduce the dimension of word tokens
  * Projection to latent space
- Positional Encoding
  * To track the relative position of the words
:::

---


## Self Attention

![](/Images/attention_5.png)

---

## Self Attention

![](/Images/self_attention_working.png){width=120%}

---

## Self Attention


![](/Images/output.png)

---


## Why Multi-Head Attention

::: {.incremental}
- It expands the models ability to focus on different positions
- It gives the attention layer multiple "representation subspaces" <br/>
![](/Images/multi_head_rep.png){height=4in}
:::

---

## Importance of Attention

::: {.incremental}
- Encoder providing a context to the decoder query by providing keys and values
- Each position in the encoder can attend to all positions in the previous layer of encoder
- Each position in decoder attending to all positions in the decoder
:::

---


## Skip connections

::: {.incremental}
- Skip connection help a word to pay attention to its own position
- Keep the gradients smooth
- ![](/Images/skip_connections_gd.png)

:::

---


## Steps in Decoder

![](/Images/steps_in_decoding.png)

---



## Adapting Attention to Vision

---

## Vision Transformer

![ViT Architecture](/Images/vit_arch.png)

---

## ViT Vs CNN

::: {.incremental}
- Inductive Bias and Locality Vs Global <br/>
![](/Images/inductive_bias.png){height=5in}
:::

--- 


## ViT Vs CNN

::: {.incremental}
- Inductive Bias and Locality Vs Global
- Flexibility
- CNN works with less amount of data than ViT
- **Specifically, if ViT is trained on datasets with more than 14M (at least) images it can approach or beat state-of-the-art CNNs.**
:::
--- 

## ViT Vs CNN

::: {.incremental}
- Transformer models are more memory efficient than ResNet models
- ViT are prone to over-fitting due to their flexibility
- Transformers can learn meaningful information even in the lowest layers
:::

---


## ViT Vs CNN

::: {.incremental}
- `ViT reaches 84.86% top-1 accuracy on ImageNet with only 10 examples per class.`
- ViT is suitable for Transfer learning
- ViTs are robust against data corruptions, image occlusions and adversarial attacks
:::

---

## Hybrid Architectures

::: {.incremental}
- CNN is used to extract features
- The extracted features are used by the transformers
:::

---


## Use Case Discussion

---

## Problem Statement

::: {.incremental}
- Monitoring when the children are in danger of leaving the front yard
- Predict when childrean are about to leave the yard to trigger the alarm
- We have videos of children playing sports
:::

---


## Approach

::: {.incremental}
- Object Detection
- Train a ML model on the object detection output
:::

---

## Object Detection with DETR

- DEtection TRansformer(DETR)
![](/Images/detr.png)


---

## Object Detection with DETR

![](/Images/detr_big_arch.png)

---

## Object Detection with DETR

![](/Images/detr_big_arch.png)

---

## Object Detection with DETR

![](/Images/detr_example.png)

---


## Why DETR

::: {.incremental}
- Hand-crafted anchors not required
- They don't require customized layers
- Predict all objects at once
- Post-processing not required for predicting bounding boxes
- Attention maps can be used for Interpretation
:::

---


## Why DETR

![](/Images/detr_atten_map.png)

---


## Why DETR

::: {.incremental}
- What if object detection model doesn't work?
- A segmentation head can be trained on top of a pre-trained DETR
:::

---

## Why DETR

![](/Images/detr_seg.png)

---


## Why DETR

![](/Images/detr_seg.png)

---


## Why DETR

::: {.incremental}
- We can get the FPS for processing videos
- Pre-trained Pytorch models and code available
:::

---

## Considerations

::: {.incremental}
- Collect and train the model on low quality images
- Amount of data available
- Training time available
- Importance of Interpretability
- Deployment requirements
  * latency 
  * Model size
  * Inference cost
:::

---

## Data Collection

::: {.incremental}
- Brainstorming how data needs to be annotated
- Standardizing the definitions
- Collecting Diversified data - Different yards, balls, walls, seasons etc
- Labeling the data - Quality Vs Quantity
- Discussing ambigious cases with labelers and keep improving
:::

---



## Modelling

::: {.incremental}

`Using a pre-trained model is both more cost-efficient and leads to better results`

:::

---

## How to select a pre-trained model

::: {.incremental}
- Spot check all the available pre-trained models (expensive)
- Select a single pre-trained model based on  
  * Amount of data used for training
  * Varied upstream data
  * Best upstream validation performance    
* `Cheaper strategy works equally well as the more expensive strategy in the majority of scenarios`
* [How to train your ViT - Research paper](https://arxiv.org/pdf/2106.10270.pdf)
:::

---

## Validation

::: {.incremental}
- False alarms are better than not raising alarm when necessary
- Recall is more important in this case 
- Too many false alarms will reduce the customer satisfaction
- Improve Recall while maintaining Precision at an acceptable level
:::

---

## Validation

::: {.incremental}
- FPS
- mAP for object detection
- Recall, Precision and F1 for the classification
:::

---

## Deployment

::: {.incremental}
- Frame sampling instead of predicting on all frames?
- Deployment using platforms like Ray for effective GPU utilization 
- Deployment at Edge to meet latency requirements - TensorRT
- Use AB testing framework to deploy new models
:::

---

## Continual Learning

::: {.incremental}
- Continual learning suits deep learning models
- Incentivize customers to label the data in real time 
- Update the model parameters in real time
- Continously monitor the model performance
:::

---

## Tool Suggestion for Monitoring

::: {.incremental}
- Fiftyone <br/br>
![](/Images/fiftyone_R_CNN.png){height=5in}
:::

---

## Summary

::: {.incremental}
- Start simple 
- Small improvements on regular basis
- Lookout for new discovery in the field
- Get Feedback, Iterate, Improve
- Keep the cycle going
:::


