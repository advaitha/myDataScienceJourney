{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Inception, ResNet and DenseNet Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48748/1860587221.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg','pdf') # for export\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg','pdf') # for export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Module "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Inception Module](/Images/inception_module.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self,c_in, c_red: dict, c_out:dict, act_fn):\n",
    "        \"\"\"_summary_\n",
    "       Inputs:\n",
    "            c_in - Number of input feature maps from the previous layers\n",
    "            c_red - Dictionary with keys \"3x3\" and \"5x5\" specifying the output of the dimensionality reducing 1x1 convolutions\n",
    "            c_out - Dictionary with keys \"1x1\", \"3x3\", \"5x5\", and \"max\"\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 1x1 convolution branch\n",
    "        self.conv_1x1 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out[\"1x1\"],kernel_size=1),\n",
    "            nn.BatchNorm2d(c_out[\"1x1\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "\n",
    "        # 3x3 convolution branch\n",
    "        self.conv_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"3x3\"],kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"3x3\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"3x3\"],c_out[\"3x3\"],kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(c_out[\"3x3\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "\n",
    "        # 5x5 convolution branch\n",
    "        self.conv_5x5 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"5x5\"],kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"5x5\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"5x5\"],c_out[\"5x5\"],kernel_size=5,padding=2),\n",
    "            nn.BatchNorm2d(c_out[\"5x5\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "\n",
    "        # Max-pool branch\n",
    "        self.max_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3,padding=1,stride=1),\n",
    "            nn.Conv2D(c_in,c_out[\"max\"],kernel_size=1),\n",
    "            nn.BatchNorm2d(c_out[\"max\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "\n",
    "        def forward(self,x):\n",
    "            x_1x1 = self.conv_1x1(x)\n",
    "            x_3x3 = self.conv_3x3(x)\n",
    "            x_5x5 = self.conv_5x5(x)\n",
    "            x_max = self.max_pool(x)\n",
    "            x_out = torch.cat([x_1x1, x_3x3, x_5x5,x_max],dim=1)\n",
    "            return x_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ResNet comes in many variants\n",
    "* Here we look into two variants - The original ResNet and the Pre-Activation ResNet Block\n",
    "* In original ResNet a non-linear activation is applied after the skip Connection\n",
    "* In pre-activation ResNet a non-linear activation at the beggining of F. For deep networks, this has shown to perform better as gradient flow is guaranteed to have the indentity matrix and is not harmed by any non-linear activation applied to it\n",
    "* We dimensions of x and f(x) should be same\n",
    "* ![Two variants of ResNet](/Images/resnet_types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original ResNet Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self,c_in,act_fn,subsample=False,c_out=-1):\n",
    "        \"\"\"_summary_\n",
    "            Inputs:\n",
    "            c_in - Number of input features\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "            subsample - If True, we want to apply a stride inside the block and reduce the output shape by 2 in height and width\n",
    "            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "\n",
    "        # Network F\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in,c_out,kernel_size=3,padding=1,stride=1 if not subsample else 2, bias=False), # No bias needed as the Batch Norm handles it\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.conv2d(c_out,c_out,kernel_size=3,padding=1, bias=False),\n",
    "            nn.BatchNorm2D(c_out)       \n",
    "        )\n",
    "\n",
    "        # 1x1 convolution with stride 2 means we take the upper left value, and transform it to new output size\n",
    "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if subsample else None\n",
    "\n",
    "        def foward(self, x):\n",
    "            z = self.net(x)\n",
    "            if self.downsample is not None:\n",
    "                x = self.downsample(x)\n",
    "            out = z + x\n",
    "            out = self.act_fn(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActResNetBlock(nn.Module):\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
    "        \"\"\"_summary_\n",
    "        Inputs:\n",
    "            c_in - Number of input features\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "            subsample - If True, we want to apply a stride inside the block and reduce the output shape by 2 in height and width\n",
    "            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "\n",
    "        # Network F\n",
    "        self.Net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2D(c_out, c_out, kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=1, stride=2, bias=False)\n",
    "        ) if subsample else None\n",
    "\n",
    "        def forward(self, x):\n",
    "            z = self.Net(x)\n",
    "            if self.downsample is not None:\n",
    "                x = self.downsample(x)\n",
    "            out = z+x\n",
    "            return out    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
